{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Function to get user preferences\n",
    "def get_user_preferences():\n",
    "    print(\"Welcome to the Outfit Recommendation System!\")\n",
    "    print(\"Please provide your preferences:\")\n",
    "    \n",
    "    weather = input(\"Weather (e.g., sunny, rainy, cold): \")\n",
    "    occasion = input(\"Occasion (e.g., casual, formal, party): \")\n",
    "    gender = input(\"Gender (male/female): \")\n",
    "    \n",
    "    return weather, occasion, gender\n",
    "\n",
    "# Function to load image dataset\n",
    "def load_image_dataset(dataset_path):\n",
    "    dataset = {}\n",
    "    for category in os.listdir(dataset_path):\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            dataset[category] = [os.path.join(category_path, f) for f in os.listdir(category_path)]\n",
    "    return dataset\n",
    "\n",
    "# Function to extract features from images using a trained CNN model\n",
    "def extract_features_cnn(model, dataset):\n",
    "    features = []\n",
    "    for category, image_paths in dataset.items():\n",
    "        for img_path in image_paths:\n",
    "            img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            feature = model.predict(img_array)\n",
    "            features.append(feature.flatten())\n",
    "    return np.array(features)\n",
    "\n",
    "# Function to recommend outfit based on user preferences\n",
    "def recommend_outfit(weather, occasion, gender):\n",
    "    # Filter dataset based on user preferences\n",
    "    filtered_images = []\n",
    "    for category, image_paths in image_dataset.items():\n",
    "        if weather in category.lower() and occasion in category.lower() and gender in category.lower():\n",
    "            filtered_images.extend(image_paths)\n",
    "    \n",
    "    # Extract features for filtered images\n",
    "    filtered_features = extract_features_cnn(cnn_model, {'filtered_images': filtered_images})\n",
    "    \n",
    "    # Find nearest neighbors\n",
    "    distances, indices = knn_model.kneighbors(filtered_features)\n",
    "    \n",
    "    # Get recommended outfits\n",
    "    recommended_outfits = []\n",
    "    for neighbor_indices in indices:\n",
    "        for idx in neighbor_indices:\n",
    "            recommended_outfits.append(filtered_images[idx])\n",
    "    \n",
    "    # Count frequency of each recommended outfit\n",
    "    outfit_counter = Counter(recommended_outfits)\n",
    "    \n",
    "    # Return top recommended outfits\n",
    "    top_outfits = outfit_counter.most_common(5)  # Get top 5 recommended outfits\n",
    "    return top_outfits\n",
    "\n",
    "# Define model architecture\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess images using ImageDataGenerator\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# Get user preferences\n",
    "weather, occasion, gender = get_user_preferences()\n",
    "\n",
    "# Load image dataset\n",
    "dataset_path = 'path/to/your/image/dataset'\n",
    "image_dataset = load_image_dataset(dataset_path)\n",
    "\n",
    "# Load pre-trained ResNet50 model for feature extraction\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Extract features from image dataset using the pre-trained ResNet50 model\n",
    "cnn_features = extract_features_cnn(resnet_model, image_dataset)\n",
    "\n",
    "# Build KNN model\n",
    "knn_model = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "knn_model.fit(cnn_features)\n",
    "\n",
    "# Define image dimensions and number of classes\n",
    "img_height, img_width = 150, 150  # Adjust based on your image dataset dimensions\n",
    "num_classes = len(image_dataset)  # Number of categories/classes\n",
    "\n",
    "# Create CNN model\n",
    "cnn_model = create_cnn_model((img_height, img_width, 3))\n",
    "\n",
    "# Compile CNN model\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             validation_split=0.2)  # Split data into training and validation sets\n",
    "\n",
    "# Load and preprocess images using ImageDataGenerator\n",
    "train_generator = datagen.flow_from_directory(dataset_path,\n",
    "                                              target_size=(img_height, img_width),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              subset='training')  # Use training subset\n",
    "validation_generator = datagen.flow_from_directory(dataset_path,\n",
    "                                                   target_size=(img_height, img_width),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   subset='validation')  # Use validation subset\n",
    "\n",
    "# Train the CNN model\n",
    "history = cnn_model.fit(train_generator,\n",
    "                        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "                        epochs=10)  # Adjust number of epochs as needed\n",
    "\n",
    "# Evaluate CNN model\n",
    "loss, accuracy = cnn_model.evaluate(validation_generator)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "# Recommend outfit based on user preferences\n",
    "recommended_outfits = recommend_outfit(weather, occasion, gender)\n",
    "print(\"Top 5 recommended outfits:\")\n",
    "for outfit, count in recommended_outfits:\n",
    "    print(outfit, \"-\", count, \"occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
